<h1 align="center"><strong>GPT-2 Shakespeare Fine-Tuning with FastAPI Endpoint</strong></h1>

## Overview

Welcome to the **GPT2-FASTAPI** repository. This project focuses on fine-tuning the GPT-2 model on Shakespeare's works and deploying it as an endpoint using FastAPI. The endpoint allows users to input a prompt and receive text generated by the fine-tuned GPT-2 model.

## Task Description

The objective of this project is to fine-tune the GPT-2 model on Shakespeare's works and host the model for conditional text generation. The project utilizes Huggingface's `Transformers` library and FastAPI to achieve this goal.

### Requirements

- Fine-tune the GPT-2 model on the works of Shakespeare.
- Create a single endpoint that takes a string input and returns a string generated by GPT-2 using temperature sampling.

## Repository Structure

This repository contains the following files:

1. **app.py**: This script uses the fine-tuned model and tokenizer to create an endpoint using FastAPI. It handles the incoming requests, generates the text using the GPT-2 model, and returns the result.

2. **helper.py**: This helper script includes functions such as `split_dataset`, `load_dataset`, `load_data_collator`, `load_model`, `load_tokenizer`, and `llm_output`. These functions streamline the process of dataset preparation, model loading, and text generation.

3. **input.txt**: This file contains the same content as the Shakespeare.txt file used in Andrej Karpathy's tutorials. It serves as the source data for fine-tuning the GPT-2 model.

4. **requirements.txt**: Lists the required Python libraries and dependencies to run the code. You can install these dependencies using pip.

5. **start.sh**: A bash script to start the FastAPI server. Run this script to launch the application and begin sending POST requests to the endpoint.

6. **train.py**: This script is responsible for fine-tuning the GPT-2 model on the Shakespeare dataset. It includes the training loop, hyperparameter settings, and model saving functionality.

## Installation and Setup

1. **Clone the Repository**:
   - Clone this repository to your local machine using Git:

     ```bash
     git clone https://github.com/mehmetalpayy/GPT2-FASTAPI.git
     cd GPT2-FASTAPI
     ```

2. **Install Dependencies**:
   - Ensure you have Python installed on your system. Install the required libraries using pip:

     ```bash
     python3 -m pip install -r requirements.txt
     ```

3. **Start the FastAPI Server**:
   - Run the `start.sh` script to start the FastAPI server:

     ```bash
     bash start.sh
     ```

4. **Send a POST Request**:
   - After starting the server, you can send a POST request to the endpoint with a prompt string. The server will return a string generated by the fine-tuned GPT-2 model.

## Design and Engineering Decisions

- **Model Fine-Tuning**: The GPT-2 model was fine-tuned on the Shakespeare dataset with the following hyperparameters:

  - **Model**: `openai-community/gpt2`
  - **Training File Path**: `input.txt`
  - **Batch Size**: 8
  - **Save Steps**: 300
  - **Max Steps**: 9000
  - **Learning Rate**: 5e-4
  - **Weight Decay**: 0.01
  - **Logging Steps**: 300
  - **Scheduler**: Linear

  The fine-tuning process used the `TrainingArguments` from Huggingface's `Transformers` library to configure the training parameters. The model was saved after training to the specified output directory. Temperature sampling was employed to manage the variability of the generated text. The training also included logging and saving checkpoints to monitor progress and ensure model quality.

- **Optimizer Choice**: The AdamW optimizer was used for fine-tuning. AdamW improves regularization by decoupling weight decay from the gradient update, helping in preventing overfitting and leading to better generalization performance.

- **Helper Functions**: The `helper.py` script was designed to modularize the code, making it easier to manage and reuse functions across different parts of the project.

- **Endpoint Implementation**: FastAPI was chosen for its asynchronous capabilities and easy integration with machine learning models. The endpoint was designed to be simple and efficient, taking a single string input and returning the generated text.

- **Bash Script**: The `start.sh` script was created to automate the process of starting the FastAPI server, reducing the setup time for running the application.

## Limitations and Future Work

- **Overfitting**: The model may be prone to overfitting. To address this, consider:
  - **Validation**: Introduce a validation dataset to monitor performance and adjust training to prevent overfitting.
  - **Cross-Validation**: Use cross-validation to ensure generalization across different data subsets.
  - **Alternate Configurations**: Experiment with different `GPT2Config` settings or regularization techniques to reduce overfitting.


## Contributing

If you would like to contribute to this project, please follow these steps:

1. Fork the repository.
2. Create a new branch for your changes.
3. Make your modifications and commit them.
4. Submit a pull request with a detailed description of the changes.

## Contact

For any questions or feedback, please contact me at [mehmetcompeng@gmail.com](mailto:mehmetcompeng@gmail.com).

---

Thank you for visiting the GPT2-FASTAPI repository. I hope you find the project useful and informative!
